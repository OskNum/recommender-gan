{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "681137b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de00756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, product_dims, customer_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(product_dims, 64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(32, customer_dims)\n",
    "        )\n",
    "\n",
    "    def forward(self, product_vector):\n",
    "        return self.model(product_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0af3b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, customer_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(customer_dims, 64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, customer_vector):\n",
    "        return self.model(customer_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d83ae697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Products data\n",
    "products = pd.read_csv('data/products.csv')\n",
    "\n",
    "prods_final = pd.concat([\n",
    "    pd.get_dummies(products['CATEGORY'])\n",
    "], axis=1)\n",
    "prods_final['price'] = products['PRICE']/products['PRICE'].max()\n",
    "prods_final['PRODUCT_ID'] = products['ID'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17581672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer data\n",
    "customers = pd.read_csv('data/customers.csv')\n",
    "\n",
    "customers_final = pd.concat([\n",
    "    pd.get_dummies(customers['GENDER'])[['Female', 'Male']],\n",
    "    pd.get_dummies(customers['COUNTRY']),\n",
    "    pd.get_dummies(customers['TYPE'])\n",
    "], axis=1)\n",
    "customers_final['age'] = ((datetime.today() - pd.to_datetime(customers['DOB']))/timedelta(days=365)).round()/100\n",
    "customers_final['CUSTOMER_ID'] = customers['ID'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40d5d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "transactions = pd.read_csv('data/trans_small_subset.csv')[['PRODUCT_ID', 'CUSTOMER_ID']].iloc[0:500000]\n",
    "X = transactions.merge(prods_final, how='left', on='PRODUCT_ID').drop(columns=['PRODUCT_ID', 'CUSTOMER_ID'])\n",
    "y = transactions.merge(customers_final, how='left', on='CUSTOMER_ID').drop(columns=['PRODUCT_ID', 'CUSTOMER_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04eb6bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nans_mask = X.isna().all(axis=1)\n",
    "X = X[~X_nans_mask]\n",
    "y = y[~X_nans_mask]\n",
    "\n",
    "y_nans_mask = y.isna().all(axis=1)\n",
    "X = X[~y_nans_mask].reset_index(drop=True)\n",
    "y = y[~y_nans_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc30a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "batch_size = 1024\n",
    "lr = 3e-4\n",
    "num_epochs = 50\n",
    "product_dims = len(X.columns)\n",
    "customer_dims = len(y.columns)\n",
    "disc_input_dims = product_dims + customer_dims\n",
    "fixed_noise = torch.randn((batch_size, product_dims)).to(device)\n",
    "step = 0\n",
    "\n",
    "disc = Discriminator(disc_input_dims).to(device)\n",
    "gen = Generator(product_dims, customer_dims).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "\n",
    "train_inds = random.sample(list(X.index.values), int(train_size*len(X.index)))\n",
    "input_data = torch.tensor(X.iloc[train_inds].values.astype(np.float32))\n",
    "true_positive = torch.tensor(y.iloc[train_inds].values.astype(np.float32))\n",
    "labels = torch.ones_like(input_data)\n",
    "train_dataset = TensorDataset(\n",
    "    input_data,\n",
    "    true_positive\n",
    ")\n",
    "loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64727a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] \\ Step [1/336] \\ Loss D: 0.694, Loss G: 0.771\n",
      "tensor([[-0.029,  0.087, -0.028,  ...,  0.178,  0.123,  0.004],\n",
      "        [-0.034,  0.085, -0.027,  ...,  0.176,  0.123,  0.002],\n",
      "        [-0.036,  0.087, -0.029,  ...,  0.179,  0.120,  0.002],\n",
      "        ...,\n",
      "        [-0.035,  0.082, -0.033,  ...,  0.178,  0.121,  0.004],\n",
      "        [-0.037,  0.087, -0.028,  ...,  0.181,  0.121,  0.001],\n",
      "        [-0.036,  0.087, -0.029,  ...,  0.180,  0.121,  0.000]])\n",
      "Epoch [1/50] \\ Step [1/336] \\ Loss D: 0.696, Loss G: 0.699\n",
      "Epoch [2/50] \\ Step [1/336] \\ Loss D: 0.704, Loss G: 0.709\n",
      "Epoch [3/50] \\ Step [1/336] \\ Loss D: 0.720, Loss G: 0.696\n",
      "Epoch [4/50] \\ Step [1/336] \\ Loss D: 0.697, Loss G: 0.686\n",
      "Epoch [5/50] \\ Step [1/336] \\ Loss D: 0.689, Loss G: 0.698\n",
      "tensor([[    -0.716,      4.855,     -3.047,  ...,     -3.284,      4.115,\n",
      "             -0.308],\n",
      "        [    -0.630,      4.218,     -2.567,  ...,     -2.777,      3.542,\n",
      "             -0.218],\n",
      "        [    -0.424,      2.932,     -1.623,  ...,     -1.813,      2.428,\n",
      "             -0.100],\n",
      "        ...,\n",
      "        [    -0.383,      2.619,     -1.384,  ...,     -1.587,      2.155,\n",
      "             -0.078],\n",
      "        [    -0.991,      6.579,     -4.304,  ...,     -4.608,      5.618,\n",
      "             -0.513],\n",
      "        [    -0.361,      2.805,     -1.612,  ...,     -1.675,      2.354,\n",
      "             -0.003]])\n",
      "Epoch [6/50] \\ Step [1/336] \\ Loss D: 0.688, Loss G: 0.716\n",
      "Epoch [7/50] \\ Step [1/336] \\ Loss D: 0.677, Loss G: 0.717\n",
      "Epoch [8/50] \\ Step [1/336] \\ Loss D: 0.698, Loss G: 0.684\n",
      "Epoch [9/50] \\ Step [1/336] \\ Loss D: 0.697, Loss G: 0.669\n",
      "Epoch [10/50] \\ Step [1/336] \\ Loss D: 0.624, Loss G: 0.888\n",
      "tensor([[-0.181, -0.911,  0.411,  ...,  0.016, -0.069, -0.186],\n",
      "        [-0.048, -0.505,  0.382,  ...,  0.048, -0.010,  0.013],\n",
      "        [ 0.217,  0.507,  0.511,  ...,  0.175, -0.036,  0.171],\n",
      "        ...,\n",
      "        [ 0.136, -0.141,  0.413,  ...,  0.081,  0.098,  0.151],\n",
      "        [-0.162, -0.766,  0.394,  ...,  0.020, -0.043, -0.150],\n",
      "        [ 0.045, -0.304,  0.452,  ...,  0.015,  0.025,  0.089]])\n",
      "Epoch [11/50] \\ Step [1/336] \\ Loss D: 0.698, Loss G: 0.680\n",
      "Epoch [12/50] \\ Step [1/336] \\ Loss D: 0.695, Loss G: 0.692\n",
      "Epoch [13/50] \\ Step [1/336] \\ Loss D: 0.682, Loss G: 0.657\n",
      "Epoch [14/50] \\ Step [1/336] \\ Loss D: 0.781, Loss G: 0.553\n",
      "Epoch [15/50] \\ Step [1/336] \\ Loss D: 0.677, Loss G: 0.719\n",
      "tensor([[ 0.352, -0.055,  1.992,  ...,  1.504, -0.805,  1.082],\n",
      "        [ 0.674,  0.160,  0.943,  ...,  0.789, -0.066,  0.530],\n",
      "        [ 0.448,  0.234,  0.660,  ...,  0.154,  0.157,  0.357],\n",
      "        ...,\n",
      "        [ 0.355,  0.149,  1.321,  ...,  0.661, -0.277,  0.760],\n",
      "        [ 0.706,  0.079,  1.286,  ...,  1.110, -0.229,  0.599],\n",
      "        [ 0.438,  0.174,  0.833,  ...,  0.674, -0.124,  0.571]])\n",
      "Epoch [16/50] \\ Step [1/336] \\ Loss D: 0.727, Loss G: 0.680\n",
      "Epoch [17/50] \\ Step [1/336] \\ Loss D: 0.699, Loss G: 0.716\n",
      "Epoch [18/50] \\ Step [1/336] \\ Loss D: 0.670, Loss G: 0.719\n",
      "Epoch [19/50] \\ Step [1/336] \\ Loss D: 0.746, Loss G: 0.688\n",
      "Epoch [20/50] \\ Step [1/336] \\ Loss D: 0.624, Loss G: 0.832\n",
      "tensor([[ 1.074,  0.276, -2.211,  ...,  0.185,  0.113, -0.689],\n",
      "        [ 0.996, -0.204, -1.204,  ...,  0.486,  0.369, -0.032],\n",
      "        [ 1.735, -0.681, -0.911,  ...,  0.774,  0.802,  0.288],\n",
      "        ...,\n",
      "        [ 1.187, -0.170, -1.576,  ...,  0.484,  0.376, -0.248],\n",
      "        [ 1.157, -0.128, -1.862,  ...,  0.383,  0.193, -0.402],\n",
      "        [ 1.314, -0.258, -1.893,  ...,  0.611,  0.210, -0.337]])\n",
      "Epoch [21/50] \\ Step [1/336] \\ Loss D: 0.766, Loss G: 0.649\n",
      "Epoch [22/50] \\ Step [1/336] \\ Loss D: 0.782, Loss G: 0.616\n",
      "Epoch [23/50] \\ Step [1/336] \\ Loss D: 0.676, Loss G: 0.755\n",
      "Epoch [24/50] \\ Step [1/336] \\ Loss D: 0.673, Loss G: 0.734\n",
      "Epoch [25/50] \\ Step [1/336] \\ Loss D: 0.674, Loss G: 0.698\n",
      "tensor([[-0.434,  2.835, -1.888,  ...,  0.316, -0.642,  0.624],\n",
      "        [ 0.246,  0.699,  0.565,  ...,  0.633,  0.224,  0.412],\n",
      "        [ 0.904,  0.075, -0.130,  ..., -0.248, -0.743,  0.428],\n",
      "        ...,\n",
      "        [ 0.550,  0.458, -0.167,  ..., -0.104, -0.345,  0.417],\n",
      "        [ 0.230,  0.973, -0.452,  ..., -0.173, -0.594,  0.518],\n",
      "        [ 0.315,  0.569, -0.129,  ...,  0.239,  0.101,  0.339]])\n",
      "Epoch [26/50] \\ Step [1/336] \\ Loss D: 0.698, Loss G: 0.684\n",
      "Epoch [27/50] \\ Step [1/336] \\ Loss D: 0.698, Loss G: 0.711\n",
      "Epoch [28/50] \\ Step [1/336] \\ Loss D: 0.676, Loss G: 0.746\n",
      "Epoch [29/50] \\ Step [1/336] \\ Loss D: 0.650, Loss G: 0.758\n",
      "Epoch [30/50] \\ Step [1/336] \\ Loss D: 0.719, Loss G: 0.676\n",
      "tensor([[ 1.014, -0.053, -0.198,  ...,  0.541, -0.493,  0.102],\n",
      "        [ 0.973, -0.192, -0.333,  ...,  0.371, -0.421,  0.140],\n",
      "        [ 1.491,  0.322, -0.066,  ...,  1.403, -0.903,  0.056],\n",
      "        ...,\n",
      "        [ 1.000,  0.065, -0.181,  ...,  0.560, -0.477,  0.105],\n",
      "        [ 1.253,  0.011, -0.228,  ...,  0.677, -0.370,  0.038],\n",
      "        [ 1.140, -0.232, -0.438,  ...,  0.285, -0.126,  0.125]])\n",
      "Epoch [31/50] \\ Step [1/336] \\ Loss D: 0.623, Loss G: 0.841\n",
      "Epoch [32/50] \\ Step [1/336] \\ Loss D: 0.719, Loss G: 0.644\n",
      "Epoch [33/50] \\ Step [1/336] \\ Loss D: 0.721, Loss G: 0.745\n",
      "Epoch [34/50] \\ Step [1/336] \\ Loss D: 0.691, Loss G: 0.681\n",
      "Epoch [35/50] \\ Step [1/336] \\ Loss D: 0.714, Loss G: 0.758\n",
      "tensor([[    -0.367,      2.313,      0.145,  ...,     -1.705,      4.115,\n",
      "              0.015],\n",
      "        [    -0.484,      2.819,      0.228,  ...,     -2.523,      5.158,\n",
      "             -0.064],\n",
      "        [    -0.609,      2.903,      0.370,  ...,     -2.174,      4.743,\n",
      "              0.013],\n",
      "        ...,\n",
      "        [    -0.992,      3.139,      0.735,  ...,     -1.838,      4.428,\n",
      "             -0.034],\n",
      "        [    -1.154,      4.105,      0.730,  ...,     -3.105,      6.370,\n",
      "             -0.123],\n",
      "        [    -0.419,      2.187,      0.339,  ...,     -1.495,      3.621,\n",
      "             -0.003]])\n",
      "Epoch [36/50] \\ Step [1/336] \\ Loss D: 0.782, Loss G: 0.580\n",
      "Epoch [37/50] \\ Step [1/336] \\ Loss D: 0.689, Loss G: 0.679\n",
      "Epoch [38/50] \\ Step [1/336] \\ Loss D: 0.668, Loss G: 0.841\n",
      "Epoch [39/50] \\ Step [1/336] \\ Loss D: 0.764, Loss G: 0.610\n",
      "Epoch [40/50] \\ Step [1/336] \\ Loss D: 0.645, Loss G: 0.734\n",
      "tensor([[-1.335,  2.748,  1.096,  ..., -0.511,  1.425,  0.026],\n",
      "        [-1.106,  2.534,  1.150,  ..., -0.651,  1.359,  0.019],\n",
      "        [ 0.388,  0.577,  0.514,  ..., -0.053,  0.628,  0.234],\n",
      "        ...,\n",
      "        [-0.557,  1.442, -0.008,  ...,  0.427,  0.063,  0.320],\n",
      "        [-0.119,  1.166,  0.763,  ..., -0.432,  0.908,  0.092],\n",
      "        [-1.233,  2.474,  0.718,  ..., -0.422,  1.092,  0.045]])\n",
      "Epoch [41/50] \\ Step [1/336] \\ Loss D: 0.803, Loss G: 0.481\n",
      "Epoch [42/50] \\ Step [1/336] \\ Loss D: 0.802, Loss G: 0.480\n",
      "Epoch [43/50] \\ Step [1/336] \\ Loss D: 0.434, Loss G: 1.019\n",
      "Epoch [44/50] \\ Step [1/336] \\ Loss D: 0.453, Loss G: 1.043\n",
      "Epoch [45/50] \\ Step [1/336] \\ Loss D: 0.292, Loss G: 1.762\n",
      "tensor([[ 0.123,  0.622,  0.113,  ..., -0.022, -0.489,  0.006],\n",
      "        [ 0.040,  0.602,  0.392,  ..., -0.288,  0.155,  0.156],\n",
      "        [ 0.188,  0.455, -0.669,  ...,  0.114, -0.255,  0.015],\n",
      "        ...,\n",
      "        [ 0.148,  0.508, -0.171,  ...,  0.191, -0.190,  0.124],\n",
      "        [ 0.176,  0.593,  0.383,  ...,  0.139, -0.226,  0.111],\n",
      "        [-0.387,  0.839, -0.112,  ..., -0.008, -0.270, -0.035]])\n",
      "Epoch [46/50] \\ Step [1/336] \\ Loss D: 0.363, Loss G: 1.024\n",
      "Epoch [47/50] \\ Step [1/336] \\ Loss D: 0.301, Loss G: 1.481\n",
      "Epoch [48/50] \\ Step [1/336] \\ Loss D: 0.289, Loss G: 1.853\n",
      "Epoch [49/50] \\ Step [1/336] \\ Loss D: 0.241, Loss G: 2.138\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=3, sci_mode=False, profile='default')\n",
    "\n",
    "n_total_steps = len(loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (input_prod, true_positive) in enumerate(loader):\n",
    "        input_prod = input_prod.to(device)\n",
    "        batch_size = input_prod.shape[0]\n",
    "        \n",
    "        # Train Discriminator: max log(D(real)) + log(1 - D(G(z)))\n",
    "        #noise = torch.randn(batch_size, product_dims)\n",
    "        disc_input_tp = torch.cat((true_positive, input_prod), 1)\n",
    "        disc_tp = disc(disc_input_tp).view(-1)\n",
    "        lossD_tp = criterion(disc_tp, torch.ones_like(disc_tp))\n",
    "        \n",
    "        fake = gen(input_prod)\n",
    "        disc_input_fake = torch.cat((fake, input_prod), 1)\n",
    "        disc_fake = disc(disc_input_fake).view(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_tp + lossD_fake)/2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "        \n",
    "        # Train Generator min log(1 - D(G(z))) -> max log(D(G(z)))\n",
    "        output = disc(disc_input_fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        if batch_idx == 0:# or ((batch_idx + 1) % 50 == 0):\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}] \\ \"\n",
    "                f\"Step [{batch_idx + 1}/{n_total_steps}] \\ \"\n",
    "                f\"Loss D: {lossD:.3f}, Loss G: {lossG:.3f}\"\n",
    "            )\n",
    "            \n",
    "            if epoch % 5 == 0:\n",
    "                with torch.no_grad():\n",
    "                    fake = gen(fixed_noise)\n",
    "                    print(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abef15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(X[~X.index.isin(train_inds)].values.astype(np.float32)),\n",
    "    torch.tensor(y[~y.index.isin(train_inds)].values.astype(np.float32))\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd7737",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f73830",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('data/products.csv')\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa7dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(products['CATEGORY']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7b58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([\n",
    "    pd.get_dummies(products['CATEGORY'])\n",
    "], axis=1)\n",
    "X['price'] = products['PRICE']/products['PRICE'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236faed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1588b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
