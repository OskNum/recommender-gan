{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "681137b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de00756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, product_dims, customer_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(product_dims, 64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(64, customer_dims),\n",
    "        )\n",
    "\n",
    "    def forward(self, product_vector):\n",
    "        return self.model(product_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0af3b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, customer_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(customer_dims, 64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, customer_vector):\n",
    "        return self.model(customer_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b088b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = pd.read_csv('data/customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef52cfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>DOB</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>EMAIL</th>\n",
       "      <th>PHONE_NUMBER</th>\n",
       "      <th>POST_CODE</th>\n",
       "      <th>CITY</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>POST_SUBSCRIBED</th>\n",
       "      <th>SMS_SUBSCRIBED</th>\n",
       "      <th>EMAIL_SUBSCRIBED</th>\n",
       "      <th>PHONE_SUBSCRIBED</th>\n",
       "      <th>SOCIAL_SUBSCRIBED</th>\n",
       "      <th>ANONYMISE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3e0698d7a4</td>\n",
       "      <td>New</td>\n",
       "      <td>Male</td>\n",
       "      <td>1988-04-16</td>\n",
       "      <td>Zelda</td>\n",
       "      <td>Schene</td>\n",
       "      <td>Zelda.SCHENE@yahoo.com</td>\n",
       "      <td>799947361</td>\n",
       "      <td>BH16</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>UK</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3e06a74d39</td>\n",
       "      <td>Lookers</td>\n",
       "      <td>Male</td>\n",
       "      <td>2003-04-13</td>\n",
       "      <td>Betty</td>\n",
       "      <td>Asherman</td>\n",
       "      <td>Betty.ASHERMAN@yahoo.com</td>\n",
       "      <td>799947361</td>\n",
       "      <td>M1</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3e06b7960c</td>\n",
       "      <td>Loyal</td>\n",
       "      <td>Male</td>\n",
       "      <td>1972-04-20</td>\n",
       "      <td>Gusta</td>\n",
       "      <td>Leibowitz</td>\n",
       "      <td>Gusta.LEIBOWITZ@yahoo.com</td>\n",
       "      <td>799947361</td>\n",
       "      <td>BH16</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3e06ed2cfb</td>\n",
       "      <td>Need-based</td>\n",
       "      <td>Male</td>\n",
       "      <td>2002-04-13</td>\n",
       "      <td>Mona</td>\n",
       "      <td>Roca</td>\n",
       "      <td>Mona.ROCA@yahoo.com</td>\n",
       "      <td>799947361</td>\n",
       "      <td>BH16</td>\n",
       "      <td>Austin</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3e07060e00</td>\n",
       "      <td>Loyal</td>\n",
       "      <td>Female</td>\n",
       "      <td>1998-04-14</td>\n",
       "      <td>Lesley</td>\n",
       "      <td>Bieck</td>\n",
       "      <td>Lesley.BIECK@yahoo.com</td>\n",
       "      <td>799947361</td>\n",
       "      <td>M1</td>\n",
       "      <td>Gothenburg</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID        TYPE  GENDER         DOB FIRST_NAME  LAST_NAME  \\\n",
       "0  3e0698d7a4         New    Male  1988-04-16      Zelda     Schene   \n",
       "1  3e06a74d39     Lookers    Male  2003-04-13      Betty   Asherman   \n",
       "2  3e06b7960c       Loyal    Male  1972-04-20      Gusta  Leibowitz   \n",
       "3  3e06ed2cfb  Need-based    Male  2002-04-13       Mona       Roca   \n",
       "4  3e07060e00       Loyal  Female  1998-04-14     Lesley      Bieck   \n",
       "\n",
       "                       EMAIL  PHONE_NUMBER POST_CODE        CITY COUNTRY  \\\n",
       "0     Zelda.SCHENE@yahoo.com     799947361      BH16   Liverpool      UK   \n",
       "1   Betty.ASHERMAN@yahoo.com     799947361        M1   Stockholm  Sweden   \n",
       "2  Gusta.LEIBOWITZ@yahoo.com     799947361      BH16     Seattle      US   \n",
       "3        Mona.ROCA@yahoo.com     799947361      BH16      Austin      US   \n",
       "4     Lesley.BIECK@yahoo.com     799947361        M1  Gothenburg  Sweden   \n",
       "\n",
       "   POST_SUBSCRIBED  SMS_SUBSCRIBED  EMAIL_SUBSCRIBED  PHONE_SUBSCRIBED  \\\n",
       "0             True            True              True              True   \n",
       "1             True            True              True              True   \n",
       "2             True            True              True              True   \n",
       "3             True            True              True              True   \n",
       "4             True            True              True              True   \n",
       "\n",
       "   SOCIAL_SUBSCRIBED  ANONYMISE  \n",
       "0               True       True  \n",
       "1               True       True  \n",
       "2               True       True  \n",
       "3               True       True  \n",
       "4               True       True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0dd3b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         35.0\n",
       "1         20.0\n",
       "2         51.0\n",
       "3         21.0\n",
       "4         25.0\n",
       "          ... \n",
       "536779    32.0\n",
       "536780    25.0\n",
       "536781    28.0\n",
       "536782    40.0\n",
       "536783    31.0\n",
       "Name: DOB, Length: 536784, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(customers['GENDER'])[['Female', 'Male']]\n",
    "pd.get_dummies(customers['COUNTRY'])\n",
    "pd.get_dummies(customers['TYPE'])\n",
    "((datetime.today() - pd.to_datetime(customers['DOB']))/timedelta(days=365)).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a75e7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([\n",
    "    pd.get_dummies(customers['GENDER'])[['Female', 'Male']],\n",
    "    pd.get_dummies(customers['COUNTRY']),\n",
    "    pd.get_dummies(customers['TYPE'])\n",
    "], axis=1)\n",
    "final['age'] = ((datetime.today() - pd.to_datetime(customers['DOB']))/timedelta(days=365)).round()/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "191e299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Sweden</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "      <th>Bargain hunter</th>\n",
       "      <th>Impulse</th>\n",
       "      <th>Lookers</th>\n",
       "      <th>Loyal</th>\n",
       "      <th>Need-based</th>\n",
       "      <th>New</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536779</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536780</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536781</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536782</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536783</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536784 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Female  Male  Sweden  UK  US  Bargain hunter  Impulse  Lookers  Loyal  \\\n",
       "0            0     1       0   1   0               0        0        0      0   \n",
       "1            0     1       1   0   0               0        0        1      0   \n",
       "2            0     1       0   0   1               0        0        0      1   \n",
       "3            0     1       0   0   1               0        0        0      0   \n",
       "4            1     0       1   0   0               0        0        0      1   \n",
       "...        ...   ...     ...  ..  ..             ...      ...      ...    ...   \n",
       "536779       0     1       1   0   0               0        0        0      1   \n",
       "536780       0     1       0   1   0               0        1        0      0   \n",
       "536781       1     0       1   0   0               0        0        0      0   \n",
       "536782       1     0       0   1   0               0        0        0      0   \n",
       "536783       1     0       1   0   0               0        0        0      0   \n",
       "\n",
       "        Need-based  New   age  \n",
       "0                0    1  0.35  \n",
       "1                0    0  0.20  \n",
       "2                0    0  0.51  \n",
       "3                1    0  0.21  \n",
       "4                0    0  0.25  \n",
       "...            ...  ...   ...  \n",
       "536779           0    0  0.32  \n",
       "536780           0    0  0.25  \n",
       "536781           1    0  0.28  \n",
       "536782           0    1  0.40  \n",
       "536783           1    0  0.31  \n",
       "\n",
       "[536784 rows x 12 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dc30a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "batch_size = 1024\n",
    "lr = 3e-4\n",
    "num_epochs = 50\n",
    "customer_dims = len(final.columns)\n",
    "product_dims = 10\n",
    "fixed_noise = torch.randn((batch_size, product_dims)).to(device)\n",
    "step = 0\n",
    "\n",
    "disc = Discriminator(customer_dims).to(device)\n",
    "gen = Generator(product_dims, customer_dims).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "\n",
    "train_inds = random.sample(list(final.index.values), int(train_size*len(final.index)))\n",
    "input_data = torch.tensor(final.iloc[train_inds].values.astype(np.float32))\n",
    "labels = torch.ones_like(input_data)\n",
    "train_dataset = TensorDataset(\n",
    "    input_data,\n",
    "    labels\n",
    ")\n",
    "loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "64727a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] \\ Step [1/420] \\ Loss D: 0.6926, Loss G: 0.6559\n",
      "tensor([[-0.0140, -0.1188, -0.1028,  ..., -0.1018,  0.0619, -0.1043],\n",
      "        [-0.0398, -0.1191, -0.1014,  ..., -0.1101,  0.0680, -0.0799],\n",
      "        [-0.0441, -0.1907, -0.1022,  ..., -0.1105,  0.0747, -0.1173],\n",
      "        ...,\n",
      "        [-0.0541, -0.0834, -0.0916,  ..., -0.1065,  0.0589, -0.1102],\n",
      "        [-0.0211, -0.1038, -0.1204,  ..., -0.0861,  0.0662, -0.0829],\n",
      "        [-0.0426, -0.1001, -0.0777,  ..., -0.0813,  0.0676, -0.1026]])\n",
      "Epoch [0/50] \\ Step [50/420] \\ Loss D: 0.6557, Loss G: 0.6475\n",
      "Epoch [0/50] \\ Step [100/420] \\ Loss D: 0.6512, Loss G: 1.0890\n",
      "Epoch [0/50] \\ Step [150/420] \\ Loss D: 0.6959, Loss G: 0.7920\n",
      "Epoch [0/50] \\ Step [200/420] \\ Loss D: 0.6040, Loss G: 0.7421\n",
      "Epoch [0/50] \\ Step [250/420] \\ Loss D: 0.6879, Loss G: 0.6926\n",
      "Epoch [0/50] \\ Step [300/420] \\ Loss D: 0.5507, Loss G: 0.9104\n",
      "Epoch [0/50] \\ Step [350/420] \\ Loss D: 0.7408, Loss G: 0.9033\n",
      "Epoch [0/50] \\ Step [400/420] \\ Loss D: 0.6627, Loss G: 0.8838\n",
      "Epoch [1/50] \\ Step [1/420] \\ Loss D: 0.7019, Loss G: 0.9229\n",
      "tensor([[ 0.0809,  0.1251,  0.5219,  ..., -1.0431,  0.4178,  0.5310],\n",
      "        [ 0.0908,  0.2145,  0.6658,  ..., -1.3250,  0.4631,  0.6329],\n",
      "        [-0.0087,  0.2457,  0.7213,  ..., -1.4004,  0.5618,  0.6277],\n",
      "        ...,\n",
      "        [ 0.1322,  0.2646,  0.7185,  ..., -1.2899,  0.4618,  0.6423],\n",
      "        [ 0.1144,  0.1929,  0.5765,  ..., -1.1193,  0.4341,  0.6135],\n",
      "        [ 0.1056,  0.2226,  0.7200,  ..., -1.2743,  0.4675,  0.6317]])\n",
      "Epoch [1/50] \\ Step [50/420] \\ Loss D: 0.6315, Loss G: 0.8059\n",
      "Epoch [1/50] \\ Step [100/420] \\ Loss D: 0.6186, Loss G: 0.6680\n",
      "Epoch [1/50] \\ Step [150/420] \\ Loss D: 0.7157, Loss G: 0.9081\n",
      "Epoch [1/50] \\ Step [200/420] \\ Loss D: 0.6474, Loss G: 0.9741\n",
      "Epoch [1/50] \\ Step [250/420] \\ Loss D: 0.4049, Loss G: 1.2154\n",
      "Epoch [1/50] \\ Step [300/420] \\ Loss D: 0.6956, Loss G: 1.0963\n",
      "Epoch [1/50] \\ Step [350/420] \\ Loss D: 0.6356, Loss G: 0.9100\n",
      "Epoch [1/50] \\ Step [400/420] \\ Loss D: 0.6637, Loss G: 0.7624\n",
      "Epoch [2/50] \\ Step [1/420] \\ Loss D: 0.5162, Loss G: 1.0547\n",
      "tensor([[-0.0364,  0.0471,  0.7878,  ..., -0.2377,  0.1190,  0.6631],\n",
      "        [-0.0215,  0.1087,  0.8938,  ..., -0.2256,  0.1593,  0.7861],\n",
      "        [-0.0813,  0.0978,  0.8391,  ..., -0.2846,  0.0577,  0.6629],\n",
      "        ...,\n",
      "        [-0.0348,  0.2094,  1.0075,  ..., -0.2261,  0.2398,  0.9117],\n",
      "        [-0.1348,  0.1110,  0.9525,  ..., -0.3154,  0.1051,  0.8257],\n",
      "        [-0.0123,  0.1293,  0.8805,  ..., -0.2158,  0.1687,  0.7725]])\n",
      "Epoch [2/50] \\ Step [50/420] \\ Loss D: 0.4425, Loss G: 1.2433\n",
      "Epoch [2/50] \\ Step [100/420] \\ Loss D: 0.6845, Loss G: 1.2166\n",
      "Epoch [2/50] \\ Step [150/420] \\ Loss D: 0.5408, Loss G: 1.8466\n",
      "Epoch [2/50] \\ Step [200/420] \\ Loss D: 0.7291, Loss G: 0.7115\n",
      "Epoch [2/50] \\ Step [250/420] \\ Loss D: 0.7699, Loss G: 0.6585\n",
      "Epoch [2/50] \\ Step [300/420] \\ Loss D: 0.7117, Loss G: 0.6733\n",
      "Epoch [2/50] \\ Step [350/420] \\ Loss D: 0.6567, Loss G: 0.7407\n",
      "Epoch [2/50] \\ Step [400/420] \\ Loss D: 0.6503, Loss G: 0.7163\n",
      "Epoch [3/50] \\ Step [1/420] \\ Loss D: 0.6326, Loss G: 0.7135\n",
      "tensor([[ 0.5216,  0.4865, -0.1463,  ..., -0.1802,  0.5691,  0.2217],\n",
      "        [ 0.4299,  0.6365, -0.1747,  ..., -0.2023,  0.6428,  0.3131],\n",
      "        [ 0.5857,  0.5654, -0.1218,  ..., -0.1241,  0.5945,  0.2670],\n",
      "        ...,\n",
      "        [ 0.5174,  0.5862, -0.1373,  ..., -0.1477,  0.6101,  0.2797],\n",
      "        [ 0.6050,  0.6357, -0.1618,  ..., -0.2123,  0.6646,  0.3115],\n",
      "        [ 0.5602,  0.5029, -0.1528,  ..., -0.1647,  0.5886,  0.2267]])\n",
      "Epoch [3/50] \\ Step [50/420] \\ Loss D: 0.5727, Loss G: 0.8217\n",
      "Epoch [3/50] \\ Step [100/420] \\ Loss D: 0.5217, Loss G: 1.0168\n",
      "Epoch [3/50] \\ Step [150/420] \\ Loss D: 0.7278, Loss G: 0.8193\n",
      "Epoch [3/50] \\ Step [200/420] \\ Loss D: 0.3939, Loss G: 1.4444\n",
      "Epoch [3/50] \\ Step [250/420] \\ Loss D: 0.7040, Loss G: 1.1855\n",
      "Epoch [3/50] \\ Step [300/420] \\ Loss D: 0.6897, Loss G: 0.7647\n",
      "Epoch [3/50] \\ Step [350/420] \\ Loss D: 0.6765, Loss G: 0.6721\n",
      "Epoch [3/50] \\ Step [400/420] \\ Loss D: 0.5995, Loss G: 0.7225\n",
      "Epoch [4/50] \\ Step [1/420] \\ Loss D: 0.6134, Loss G: 0.7290\n",
      "tensor([[ 0.1292,  0.5104,  0.5865,  ..., -0.0451,  0.3567,  0.3533],\n",
      "        [ 0.2119,  0.5996,  0.7046,  ...,  0.0097,  0.4521,  0.4792],\n",
      "        [ 0.1619,  0.5362,  0.5862,  ..., -0.0311,  0.3484,  0.3271],\n",
      "        ...,\n",
      "        [ 0.2333,  0.6889,  0.7065,  ...,  0.0473,  0.4792,  0.5257],\n",
      "        [ 0.1070,  0.5409,  0.5215,  ..., -0.1213,  0.3685,  0.3152],\n",
      "        [ 0.2135,  0.5812,  0.6600,  ...,  0.0245,  0.4189,  0.4526]])\n",
      "Epoch [4/50] \\ Step [50/420] \\ Loss D: 0.5127, Loss G: 0.9785\n",
      "Epoch [4/50] \\ Step [100/420] \\ Loss D: 0.7019, Loss G: 0.7351\n",
      "Epoch [4/50] \\ Step [150/420] \\ Loss D: 0.7021, Loss G: 0.9866\n",
      "Epoch [4/50] \\ Step [200/420] \\ Loss D: 0.4987, Loss G: 1.2590\n",
      "Epoch [4/50] \\ Step [250/420] \\ Loss D: 0.3895, Loss G: 1.3974\n",
      "Epoch [4/50] \\ Step [300/420] \\ Loss D: 0.7454, Loss G: 0.7909\n",
      "Epoch [4/50] \\ Step [350/420] \\ Loss D: 0.6058, Loss G: 0.8896\n",
      "Epoch [4/50] \\ Step [400/420] \\ Loss D: 0.5036, Loss G: 0.9193\n",
      "Epoch [5/50] \\ Step [1/420] \\ Loss D: 0.4024, Loss G: 1.1621\n",
      "tensor([[ 1.6386e-01,  3.2601e-02,  3.7687e-01,  ...,  4.4225e-01,\n",
      "         -9.4130e-03,  2.9660e-01],\n",
      "        [ 1.4176e-01,  3.7962e-02,  3.7465e-01,  ...,  4.3552e-01,\n",
      "         -2.5083e-03,  3.1876e-01],\n",
      "        [ 1.8634e-01, -2.7452e-02,  3.0546e-01,  ...,  4.6532e-01,\n",
      "         -9.4474e-02,  2.6558e-01],\n",
      "        ...,\n",
      "        [ 5.8605e-01, -7.2973e-02,  1.0493e-02,  ...,  5.3322e-01,\n",
      "          7.5594e-02,  3.6496e-01],\n",
      "        [-3.5340e-04,  1.4354e-01,  5.7885e-01,  ...,  4.6151e-01,\n",
      "         -1.0763e-01,  2.3142e-01],\n",
      "        [ 3.2628e-01, -6.9909e-02,  1.0342e-01,  ...,  4.3671e-01,\n",
      "          5.9883e-02,  2.6819e-01]])\n",
      "Epoch [5/50] \\ Step [50/420] \\ Loss D: 0.5920, Loss G: 1.2881\n",
      "Epoch [5/50] \\ Step [100/420] \\ Loss D: 0.5683, Loss G: 1.3439\n",
      "Epoch [5/50] \\ Step [150/420] \\ Loss D: 0.3040, Loss G: 1.4534\n",
      "Epoch [5/50] \\ Step [200/420] \\ Loss D: 0.6419, Loss G: 0.9857\n",
      "Epoch [5/50] \\ Step [250/420] \\ Loss D: 0.5511, Loss G: 1.2900\n",
      "Epoch [5/50] \\ Step [300/420] \\ Loss D: 0.5295, Loss G: 1.3079\n",
      "Epoch [5/50] \\ Step [350/420] \\ Loss D: 0.6296, Loss G: 0.9406\n",
      "Epoch [5/50] \\ Step [400/420] \\ Loss D: 0.5015, Loss G: 1.0615\n",
      "Epoch [6/50] \\ Step [1/420] \\ Loss D: 0.5601, Loss G: 1.0638\n",
      "tensor([[ 2.0639,  0.0743,  0.1851,  ...,  0.1553, -0.6095,  0.3104],\n",
      "        [ 1.2388,  0.0307, -0.0691,  ...,  0.1362, -0.1354,  0.2926],\n",
      "        [ 1.4872,  0.0896,  0.1564,  ...,  0.0434, -0.2962,  0.1902],\n",
      "        ...,\n",
      "        [ 2.6572, -0.0369,  0.0323,  ...,  0.1615, -0.5980,  0.5098],\n",
      "        [ 1.6438,  0.1598,  0.2005,  ...,  0.1273, -0.4003,  0.2862],\n",
      "        [ 2.5364,  0.0534,  0.1665,  ...,  0.1507, -0.6870,  0.4049]])\n",
      "Epoch [6/50] \\ Step [50/420] \\ Loss D: 0.5330, Loss G: 1.1718\n",
      "Epoch [6/50] \\ Step [100/420] \\ Loss D: 0.4818, Loss G: 1.2609\n",
      "Epoch [6/50] \\ Step [150/420] \\ Loss D: 0.5817, Loss G: 0.8949\n",
      "Epoch [6/50] \\ Step [200/420] \\ Loss D: 0.7835, Loss G: 0.9859\n",
      "Epoch [6/50] \\ Step [250/420] \\ Loss D: 0.5706, Loss G: 0.8234\n",
      "Epoch [6/50] \\ Step [300/420] \\ Loss D: 0.5372, Loss G: 0.8241\n",
      "Epoch [6/50] \\ Step [350/420] \\ Loss D: 0.4704, Loss G: 1.0305\n",
      "Epoch [6/50] \\ Step [400/420] \\ Loss D: 0.5983, Loss G: 1.2325\n",
      "Epoch [7/50] \\ Step [1/420] \\ Loss D: 0.5513, Loss G: 1.2428\n",
      "tensor([[ 0.6753,  0.6927,  0.4435,  ..., -0.1476,  0.3893,  0.3723],\n",
      "        [ 0.8604,  1.0116,  0.4559,  ..., -0.2804,  0.6388,  0.6661],\n",
      "        [ 0.6069,  0.6020,  0.4275,  ..., -0.0084,  0.3895,  0.3985],\n",
      "        ...,\n",
      "        [ 0.8860,  1.0638,  0.5700,  ..., -0.3149,  0.8003,  0.6911],\n",
      "        [ 0.6235,  0.6340,  0.4248,  ...,  0.0834,  0.2853,  0.3062],\n",
      "        [ 0.9111,  1.0699,  0.5673,  ..., -0.3980,  0.6322,  0.5617]])\n",
      "Epoch [7/50] \\ Step [50/420] \\ Loss D: 0.5890, Loss G: 1.0995\n",
      "Epoch [7/50] \\ Step [100/420] \\ Loss D: 0.4923, Loss G: 0.9626\n",
      "Epoch [7/50] \\ Step [150/420] \\ Loss D: 0.4359, Loss G: 1.0785\n",
      "Epoch [7/50] \\ Step [200/420] \\ Loss D: 0.2914, Loss G: 1.9281\n",
      "Epoch [7/50] \\ Step [250/420] \\ Loss D: 0.7464, Loss G: 1.5727\n",
      "Epoch [7/50] \\ Step [300/420] \\ Loss D: 0.6151, Loss G: 1.3107\n",
      "Epoch [7/50] \\ Step [350/420] \\ Loss D: 0.4590, Loss G: 1.1078\n",
      "Epoch [7/50] \\ Step [400/420] \\ Loss D: 0.4680, Loss G: 1.0867\n",
      "Epoch [8/50] \\ Step [1/420] \\ Loss D: 0.4874, Loss G: 1.1882\n",
      "tensor([[ 0.6583, -0.0137,  0.3907,  ...,  0.6809,  0.1540,  0.3428],\n",
      "        [ 0.3355,  0.9051,  0.0408,  ...,  0.3519,  0.4703,  0.8928],\n",
      "        [ 0.5083,  0.0483,  0.4359,  ...,  0.4884,  0.2081,  0.3100],\n",
      "        ...,\n",
      "        [ 0.3536,  1.1453, -0.0409,  ...,  0.4152,  0.7003,  1.0789],\n",
      "        [ 0.6881,  0.1585,  0.2986,  ...,  0.7362,  0.2705,  0.4284],\n",
      "        [ 0.3804,  0.1233,  0.3851,  ...,  0.4380,  0.2564,  0.2932]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] \\ Step [50/420] \\ Loss D: 0.4444, Loss G: 1.2153\n",
      "Epoch [8/50] \\ Step [100/420] \\ Loss D: 0.4012, Loss G: 1.4424\n",
      "Epoch [8/50] \\ Step [150/420] \\ Loss D: 0.4895, Loss G: 1.1718\n",
      "Epoch [8/50] \\ Step [200/420] \\ Loss D: 0.3200, Loss G: 1.6712\n",
      "Epoch [8/50] \\ Step [250/420] \\ Loss D: 0.5106, Loss G: 1.4671\n",
      "Epoch [8/50] \\ Step [300/420] \\ Loss D: 0.2838, Loss G: 1.8628\n",
      "Epoch [8/50] \\ Step [350/420] \\ Loss D: 0.3787, Loss G: 1.8018\n",
      "Epoch [8/50] \\ Step [400/420] \\ Loss D: 0.4419, Loss G: 1.8933\n",
      "Epoch [9/50] \\ Step [1/420] \\ Loss D: 0.4468, Loss G: 1.7037\n",
      "tensor([[ 0.6953,  0.4231,  0.3929,  ...,  0.6976,  0.7842,  0.1792],\n",
      "        [ 0.9001,  0.2915, -0.0113,  ..., -0.1842, -0.7206,  0.3837],\n",
      "        [ 0.5465,  0.6289,  0.5885,  ...,  0.7743,  0.8091,  0.2316],\n",
      "        ...,\n",
      "        [ 0.7126,  0.4431,  0.0478,  ..., -0.1528, -0.4877,  0.3609],\n",
      "        [ 0.2446,  0.5760,  0.0725,  ...,  0.2431,  0.5348,  0.2187],\n",
      "        [ 0.6187,  0.5323,  0.8134,  ...,  0.8190,  0.7097,  0.1860]])\n",
      "Epoch [9/50] \\ Step [50/420] \\ Loss D: 0.4299, Loss G: 1.6411\n",
      "Epoch [9/50] \\ Step [100/420] \\ Loss D: 0.5090, Loss G: 1.5808\n",
      "Epoch [9/50] \\ Step [150/420] \\ Loss D: 0.3970, Loss G: 1.7698\n",
      "Epoch [9/50] \\ Step [200/420] \\ Loss D: 0.3693, Loss G: 1.7081\n",
      "Epoch [9/50] \\ Step [250/420] \\ Loss D: 0.3422, Loss G: 1.8479\n",
      "Epoch [9/50] \\ Step [300/420] \\ Loss D: 0.3572, Loss G: 1.9805\n",
      "Epoch [9/50] \\ Step [350/420] \\ Loss D: 0.3773, Loss G: 1.9626\n",
      "Epoch [9/50] \\ Step [400/420] \\ Loss D: 0.3259, Loss G: 1.9421\n",
      "Epoch [10/50] \\ Step [1/420] \\ Loss D: 0.3326, Loss G: 1.9543\n",
      "tensor([[ 0.8096,  0.0304,  0.5117,  ...,  0.3475,  0.1611,  0.3986],\n",
      "        [ 0.4707,  0.4298,  0.0906,  ...,  0.7952, -0.6996,  0.4744],\n",
      "        [ 0.8418,  0.1979,  0.2752,  ...,  0.3634,  0.6581,  0.5172],\n",
      "        ...,\n",
      "        [-0.1407,  0.9958,  0.4761,  ...,  0.7803, -0.6559,  0.4292],\n",
      "        [ 1.0307, -0.1865,  0.7969,  ...,  0.3931,  0.0698,  0.4336],\n",
      "        [-0.0294,  0.9356,  0.2780,  ...,  0.4988, -0.0096,  0.4279]])\n",
      "Epoch [10/50] \\ Step [50/420] \\ Loss D: 0.2761, Loss G: 2.3991\n",
      "Epoch [10/50] \\ Step [100/420] \\ Loss D: 0.2396, Loss G: 2.3827\n",
      "Epoch [10/50] \\ Step [150/420] \\ Loss D: 0.2271, Loss G: 2.6005\n",
      "Epoch [10/50] \\ Step [200/420] \\ Loss D: 0.2411, Loss G: 2.6454\n",
      "Epoch [10/50] \\ Step [250/420] \\ Loss D: 0.2300, Loss G: 2.8462\n",
      "Epoch [10/50] \\ Step [300/420] \\ Loss D: 0.2184, Loss G: 2.8035\n",
      "Epoch [10/50] \\ Step [350/420] \\ Loss D: 0.2129, Loss G: 3.0673\n",
      "Epoch [10/50] \\ Step [400/420] \\ Loss D: 0.2068, Loss G: 3.1743\n",
      "Epoch [11/50] \\ Step [1/420] \\ Loss D: 0.1843, Loss G: 3.2747\n",
      "tensor([[ 0.6626,  0.1807,  0.8268,  ...,  0.5282, -0.0786,  0.4271],\n",
      "        [ 0.0198,  0.7307,  0.1858,  ...,  1.1063, -0.1250,  0.4530],\n",
      "        [ 1.1982, -0.1930,  0.3934,  ...,  0.9096,  0.2756,  0.5388],\n",
      "        ...,\n",
      "        [-0.1838,  1.0333,  1.0072,  ...,  1.1255, -0.0905,  0.4557],\n",
      "        [ 0.6363,  0.2320,  0.9940,  ...,  0.0523, -0.0781,  0.4073],\n",
      "        [ 0.1293,  0.7354,  0.0742,  ...,  1.0159, -0.0245,  0.4774]])\n",
      "Epoch [11/50] \\ Step [50/420] \\ Loss D: 0.2124, Loss G: 3.1302\n",
      "Epoch [11/50] \\ Step [100/420] \\ Loss D: 0.1349, Loss G: 3.4118\n",
      "Epoch [11/50] \\ Step [150/420] \\ Loss D: 0.1537, Loss G: 3.9752\n",
      "Epoch [11/50] \\ Step [200/420] \\ Loss D: 0.0970, Loss G: 3.9292\n",
      "Epoch [11/50] \\ Step [250/420] \\ Loss D: 0.2188, Loss G: 3.4828\n",
      "Epoch [11/50] \\ Step [300/420] \\ Loss D: 0.1800, Loss G: 3.2808\n",
      "Epoch [11/50] \\ Step [350/420] \\ Loss D: 0.1677, Loss G: 3.4455\n",
      "Epoch [11/50] \\ Step [400/420] \\ Loss D: 0.1072, Loss G: 4.1007\n",
      "Epoch [12/50] \\ Step [1/420] \\ Loss D: 0.1635, Loss G: 3.9902\n",
      "tensor([[ 0.8308,  0.0797,  0.9483,  ...,  1.2697,  0.0129,  0.3937],\n",
      "        [ 0.1320,  0.6828,  0.1553,  ...,  1.3698,  0.0767,  0.3700],\n",
      "        [ 0.9373, -0.0828,  0.2382,  ...,  1.3298,  0.0018,  0.3813],\n",
      "        ...,\n",
      "        [-0.0808,  1.0214,  1.0876,  ...,  1.2375,  0.0613,  0.3584],\n",
      "        [ 0.8482,  0.0376,  1.0174,  ...,  1.0791, -0.0332,  0.4051],\n",
      "        [-0.0844,  0.8649, -0.0207,  ...,  1.1318, -0.0271,  0.3751]])\n",
      "Epoch [12/50] \\ Step [50/420] \\ Loss D: 0.1735, Loss G: 3.5333\n",
      "Epoch [12/50] \\ Step [100/420] \\ Loss D: 0.2011, Loss G: 3.7116\n",
      "Epoch [12/50] \\ Step [150/420] \\ Loss D: 0.2561, Loss G: 3.2896\n",
      "Epoch [12/50] \\ Step [200/420] \\ Loss D: 0.2005, Loss G: 3.1600\n",
      "Epoch [12/50] \\ Step [250/420] \\ Loss D: 0.1867, Loss G: 3.3114\n",
      "Epoch [12/50] \\ Step [300/420] \\ Loss D: 0.2036, Loss G: 3.3973\n",
      "Epoch [12/50] \\ Step [350/420] \\ Loss D: 0.1918, Loss G: 2.9004\n",
      "Epoch [12/50] \\ Step [400/420] \\ Loss D: 0.2070, Loss G: 2.7148\n",
      "Epoch [13/50] \\ Step [1/420] \\ Loss D: 0.1677, Loss G: 2.8059\n",
      "tensor([[ 0.9917, -0.0238,  0.9993,  ...,  0.9165, -0.0238,  0.5638],\n",
      "        [ 0.1973,  0.7355,  0.0016,  ...,  0.9504, -0.0323,  0.4934],\n",
      "        [ 0.9858, -0.0582,  0.1656,  ...,  0.8482, -0.0449,  0.5176],\n",
      "        ...,\n",
      "        [-0.0642,  1.0006,  1.0139,  ...,  0.9935, -0.0213,  0.5804],\n",
      "        [ 1.0049, -0.0289,  1.0012,  ...,  0.9108, -0.0228,  0.5680],\n",
      "        [-0.0463,  0.9842,  0.0253,  ...,  0.9209, -0.0614,  0.5003]])\n",
      "Epoch [13/50] \\ Step [50/420] \\ Loss D: 0.2838, Loss G: 2.3801\n",
      "Epoch [13/50] \\ Step [100/420] \\ Loss D: 0.1897, Loss G: 2.6360\n",
      "Epoch [13/50] \\ Step [150/420] \\ Loss D: 0.2895, Loss G: 2.3485\n",
      "Epoch [13/50] \\ Step [200/420] \\ Loss D: 0.2941, Loss G: 2.4796\n",
      "Epoch [13/50] \\ Step [250/420] \\ Loss D: 0.1951, Loss G: 2.6695\n",
      "Epoch [13/50] \\ Step [300/420] \\ Loss D: 0.2915, Loss G: 2.4320\n",
      "Epoch [13/50] \\ Step [350/420] \\ Loss D: 0.2435, Loss G: 2.2426\n",
      "Epoch [13/50] \\ Step [400/420] \\ Loss D: 0.3029, Loss G: 2.1994\n",
      "Epoch [14/50] \\ Step [1/420] \\ Loss D: 0.2605, Loss G: 2.5931\n",
      "tensor([[ 9.7835e-01, -2.6428e-02,  9.9536e-01,  ...,  1.0489e+00,\n",
      "          5.0142e-02,  2.4471e-01],\n",
      "        [-1.8603e-02,  9.0869e-01, -8.8003e-03,  ...,  1.0264e+00,\n",
      "          3.2255e-02,  2.7397e-01],\n",
      "        [ 9.5964e-01, -6.6203e-02,  2.0982e-01,  ...,  1.0178e+00,\n",
      "          3.7451e-02,  2.4385e-01],\n",
      "        ...,\n",
      "        [-6.8200e-02,  9.9782e-01,  9.9906e-01,  ...,  1.0032e+00,\n",
      "          4.2761e-02,  2.5049e-01],\n",
      "        [ 9.6862e-01, -1.8622e-02,  1.0125e+00,  ...,  1.0450e+00,\n",
      "          5.4080e-02,  2.4425e-01],\n",
      "        [-9.9028e-02,  9.9036e-01,  1.3027e-04,  ...,  9.9699e-01,\n",
      "          1.6789e-02,  2.8661e-01]])\n",
      "Epoch [14/50] \\ Step [50/420] \\ Loss D: 0.2620, Loss G: 2.4247\n",
      "Epoch [14/50] \\ Step [100/420] \\ Loss D: 0.1851, Loss G: 2.5098\n",
      "Epoch [14/50] \\ Step [150/420] \\ Loss D: 0.2204, Loss G: 2.5008\n",
      "Epoch [14/50] \\ Step [200/420] \\ Loss D: 0.2653, Loss G: 2.3494\n",
      "Epoch [14/50] \\ Step [250/420] \\ Loss D: 0.2350, Loss G: 2.5160\n",
      "Epoch [14/50] \\ Step [300/420] \\ Loss D: 0.2335, Loss G: 2.5581\n",
      "Epoch [14/50] \\ Step [350/420] \\ Loss D: 0.2448, Loss G: 2.4119\n",
      "Epoch [14/50] \\ Step [400/420] \\ Loss D: 0.2445, Loss G: 2.2730\n",
      "Epoch [15/50] \\ Step [1/420] \\ Loss D: 0.2508, Loss G: 2.2998\n",
      "tensor([[ 0.9737, -0.0077,  1.0060,  ...,  0.9641, -0.0256,  0.2972],\n",
      "        [ 0.0119,  0.9662,  0.0101,  ...,  1.0077,  0.0069,  0.2636],\n",
      "        [ 1.0020, -0.0369,  0.1273,  ...,  0.9508, -0.0188,  0.2761],\n",
      "        ...,\n",
      "        [-0.0437,  1.0137,  1.0413,  ...,  0.9913, -0.0138,  0.2876],\n",
      "        [ 0.9606, -0.0023,  1.0191,  ...,  0.9551, -0.0234,  0.2975],\n",
      "        [-0.0226,  1.0119,  0.0128,  ...,  1.0075, -0.0034,  0.2655]])\n",
      "Epoch [15/50] \\ Step [50/420] \\ Loss D: 0.2965, Loss G: 2.2745\n",
      "Epoch [15/50] \\ Step [100/420] \\ Loss D: 0.2418, Loss G: 2.2271\n",
      "Epoch [15/50] \\ Step [150/420] \\ Loss D: 0.2506, Loss G: 2.3725\n",
      "Epoch [15/50] \\ Step [200/420] \\ Loss D: 0.2569, Loss G: 2.3263\n",
      "Epoch [15/50] \\ Step [250/420] \\ Loss D: 0.2991, Loss G: 2.3149\n",
      "Epoch [15/50] \\ Step [300/420] \\ Loss D: 0.2223, Loss G: 2.2788\n",
      "Epoch [15/50] \\ Step [350/420] \\ Loss D: 0.2033, Loss G: 2.2080\n",
      "Epoch [15/50] \\ Step [400/420] \\ Loss D: 0.2266, Loss G: 2.3422\n",
      "Epoch [16/50] \\ Step [1/420] \\ Loss D: 0.3092, Loss G: 2.1722\n",
      "tensor([[ 1.0039e+00,  3.4935e-02,  9.5756e-01,  ...,  1.0101e+00,\n",
      "         -5.8540e-04,  2.1844e-01],\n",
      "        [ 1.9079e-02,  1.0327e+00, -1.1136e-02,  ...,  1.0270e+00,\n",
      "          9.2599e-03,  2.5876e-01],\n",
      "        [ 9.8341e-01,  1.2130e-02,  1.1261e-01,  ...,  9.8022e-01,\n",
      "         -1.5567e-02,  2.4312e-01],\n",
      "        ...,\n",
      "        [ 3.3621e-02,  1.0257e+00,  9.5690e-01,  ...,  1.0402e+00,\n",
      "          1.1129e-02,  2.0971e-01],\n",
      "        [ 9.9503e-01,  4.0655e-02,  9.6929e-01,  ...,  1.0092e+00,\n",
      "          1.2168e-03,  2.1766e-01],\n",
      "        [ 6.2424e-03,  1.0671e+00, -1.4964e-02,  ...,  1.0380e+00,\n",
      "          2.7022e-04,  2.7577e-01]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] \\ Step [50/420] \\ Loss D: 0.2833, Loss G: 2.3021\n",
      "Epoch [16/50] \\ Step [100/420] \\ Loss D: 0.2857, Loss G: 2.1063\n",
      "Epoch [16/50] \\ Step [150/420] \\ Loss D: 0.1960, Loss G: 2.4509\n",
      "Epoch [16/50] \\ Step [200/420] \\ Loss D: 0.2206, Loss G: 2.4046\n",
      "Epoch [16/50] \\ Step [250/420] \\ Loss D: 0.1968, Loss G: 2.2608\n",
      "Epoch [16/50] \\ Step [300/420] \\ Loss D: 0.1999, Loss G: 2.3999\n",
      "Epoch [16/50] \\ Step [350/420] \\ Loss D: 0.1957, Loss G: 2.1766\n",
      "Epoch [16/50] \\ Step [400/420] \\ Loss D: 0.2009, Loss G: 2.3286\n",
      "Epoch [17/50] \\ Step [1/420] \\ Loss D: 0.3376, Loss G: 2.1815\n",
      "tensor([[ 9.4644e-01,  1.8167e-03,  9.8826e-01,  ...,  9.3261e-01,\n",
      "         -3.1334e-02,  3.3736e-01],\n",
      "        [-1.6750e-02,  9.5042e-01,  1.8995e-02,  ...,  9.3469e-01,\n",
      "         -2.5579e-02,  3.1730e-01],\n",
      "        [ 9.5347e-01, -3.2225e-02,  9.4208e-02,  ...,  8.9380e-01,\n",
      "         -3.9513e-02,  3.2439e-01],\n",
      "        ...,\n",
      "        [-3.8916e-02,  9.1021e-01,  9.7693e-01,  ...,  8.6436e-01,\n",
      "         -2.5106e-02,  3.0091e-01],\n",
      "        [ 9.4367e-01, -2.4072e-04,  9.9809e-01,  ...,  9.2844e-01,\n",
      "         -2.9436e-02,  3.3692e-01],\n",
      "        [-3.6951e-02,  9.6782e-01,  1.5081e-02,  ...,  9.4109e-01,\n",
      "         -3.2356e-02,  3.1947e-01]])\n",
      "Epoch [17/50] \\ Step [50/420] \\ Loss D: 0.2753, Loss G: 2.3457\n",
      "Epoch [17/50] \\ Step [100/420] \\ Loss D: 0.2516, Loss G: 2.1728\n",
      "Epoch [17/50] \\ Step [150/420] \\ Loss D: 0.2492, Loss G: 2.0664\n",
      "Epoch [17/50] \\ Step [200/420] \\ Loss D: 0.2193, Loss G: 2.1818\n",
      "Epoch [17/50] \\ Step [250/420] \\ Loss D: 0.2484, Loss G: 2.2314\n",
      "Epoch [17/50] \\ Step [300/420] \\ Loss D: 0.2789, Loss G: 2.1595\n",
      "Epoch [17/50] \\ Step [350/420] \\ Loss D: 0.2557, Loss G: 2.1929\n",
      "Epoch [17/50] \\ Step [400/420] \\ Loss D: 0.2546, Loss G: 2.1506\n",
      "Epoch [18/50] \\ Step [1/420] \\ Loss D: 0.3271, Loss G: 2.1463\n",
      "tensor([[ 1.0010e+00,  2.8955e-03,  9.7665e-01,  ...,  9.8200e-01,\n",
      "         -4.9596e-04,  4.0722e-01],\n",
      "        [ 2.4978e-02,  9.9269e-01, -8.9344e-03,  ...,  9.7704e-01,\n",
      "         -2.3224e-03,  4.2289e-01],\n",
      "        [ 1.0009e+00, -1.6100e-02,  1.2214e-01,  ...,  9.4271e-01,\n",
      "         -7.9144e-03,  4.0673e-01],\n",
      "        ...,\n",
      "        [ 3.4117e-02,  9.8736e-01,  9.7606e-01,  ...,  9.7608e-01,\n",
      "         -2.1845e-03,  4.7208e-01],\n",
      "        [ 9.9178e-01,  5.8507e-03,  9.8072e-01,  ...,  9.7568e-01,\n",
      "          1.4668e-03,  4.0631e-01],\n",
      "        [ 3.3084e-02,  1.0019e+00, -8.7166e-03,  ...,  9.8014e-01,\n",
      "         -6.0821e-03,  4.4879e-01]])\n",
      "Epoch [18/50] \\ Step [50/420] \\ Loss D: 0.2017, Loss G: 2.2241\n",
      "Epoch [18/50] \\ Step [100/420] \\ Loss D: 0.2345, Loss G: 2.1613\n",
      "Epoch [18/50] \\ Step [150/420] \\ Loss D: 0.2486, Loss G: 2.1118\n",
      "Epoch [18/50] \\ Step [200/420] \\ Loss D: 0.2690, Loss G: 2.1786\n",
      "Epoch [18/50] \\ Step [250/420] \\ Loss D: 0.2789, Loss G: 2.0824\n",
      "Epoch [18/50] \\ Step [300/420] \\ Loss D: 0.2204, Loss G: 2.1115\n",
      "Epoch [18/50] \\ Step [350/420] \\ Loss D: 0.2535, Loss G: 2.1687\n",
      "Epoch [18/50] \\ Step [400/420] \\ Loss D: 0.3096, Loss G: 2.0967\n",
      "Epoch [19/50] \\ Step [1/420] \\ Loss D: 0.2670, Loss G: 2.0696\n",
      "tensor([[ 1.0117e+00, -1.7915e-02,  9.7980e-01,  ...,  9.9169e-01,\n",
      "          1.9038e-03,  2.1722e-01],\n",
      "        [-1.5572e-02,  1.0036e+00,  3.2560e-03,  ...,  9.8619e-01,\n",
      "          2.3628e-04,  2.2949e-01],\n",
      "        [ 1.0007e+00, -4.2756e-02,  2.3994e-01,  ...,  9.5780e-01,\n",
      "         -6.9330e-03,  2.2553e-01],\n",
      "        ...,\n",
      "        [ 1.6889e-02,  9.8146e-01,  9.6905e-01,  ...,  1.0138e+00,\n",
      "         -7.8761e-04,  1.7698e-01],\n",
      "        [ 1.0094e+00, -2.0222e-02,  9.7646e-01,  ...,  9.8665e-01,\n",
      "          4.0893e-03,  2.1599e-01],\n",
      "        [-1.5704e-02,  1.0165e+00,  6.4940e-03,  ...,  1.0002e+00,\n",
      "         -5.0564e-03,  2.3650e-01]])\n",
      "Epoch [19/50] \\ Step [50/420] \\ Loss D: 0.2184, Loss G: 2.0940\n",
      "Epoch [19/50] \\ Step [100/420] \\ Loss D: 0.2729, Loss G: 2.1119\n",
      "Epoch [19/50] \\ Step [150/420] \\ Loss D: 0.2851, Loss G: 1.9037\n",
      "Epoch [19/50] \\ Step [200/420] \\ Loss D: 0.2263, Loss G: 2.1052\n",
      "Epoch [19/50] \\ Step [250/420] \\ Loss D: 0.2833, Loss G: 2.2383\n",
      "Epoch [19/50] \\ Step [300/420] \\ Loss D: 0.2673, Loss G: 1.8854\n",
      "Epoch [19/50] \\ Step [350/420] \\ Loss D: 0.2296, Loss G: 2.1523\n",
      "Epoch [19/50] \\ Step [400/420] \\ Loss D: 0.2887, Loss G: 1.8910\n",
      "Epoch [20/50] \\ Step [1/420] \\ Loss D: 0.2916, Loss G: 1.9754\n",
      "tensor([[ 9.9268e-01,  1.4226e-03,  1.0014e+00,  ...,  9.8308e-01,\n",
      "          9.9871e-03,  4.7638e-01],\n",
      "        [-5.2538e-03,  9.8852e-01,  3.3913e-04,  ...,  9.9879e-01,\n",
      "          1.4625e-02,  4.5121e-01],\n",
      "        [ 1.0055e+00, -3.3787e-02,  2.0018e-01,  ...,  9.5233e-01,\n",
      "          1.1059e-02,  4.6174e-01],\n",
      "        ...,\n",
      "        [-8.9796e-03,  9.9950e-01,  9.9037e-01,  ...,  9.9796e-01,\n",
      "          2.2455e-02,  5.6431e-01],\n",
      "        [ 9.9774e-01, -5.8367e-03,  1.0050e+00,  ...,  9.7760e-01,\n",
      "          1.2043e-02,  4.7650e-01],\n",
      "        [-8.8645e-03,  1.0033e+00, -1.3013e-03,  ...,  1.0090e+00,\n",
      "          1.9837e-02,  4.7932e-01]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m disc_real \u001b[38;5;241m=\u001b[39m disc(real)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m lossD_real \u001b[38;5;241m=\u001b[39m criterion(disc_real, torch\u001b[38;5;241m.\u001b[39mones_like(disc_real))\n\u001b[1;32m---> 12\u001b[0m disc_fake \u001b[38;5;241m=\u001b[39m \u001b[43mdisc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m lossD_fake \u001b[38;5;241m=\u001b[39m criterion(disc_fake, torch\u001b[38;5;241m.\u001b[39mzeros_like(disc_fake))\n\u001b[0;32m     14\u001b[0m lossD \u001b[38;5;241m=\u001b[39m (lossD_real \u001b[38;5;241m+\u001b[39m lossD_fake)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\recommender\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[36], line 18\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[1;34m(self, customer_vector)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, customer_vector):\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustomer_vector\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\recommender\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\recommender\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\recommender\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\recommender\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_total_steps = len(loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        real = real.to(device)\n",
    "        batch_size = real.shape[0]\n",
    "        \n",
    "        # Train Discriminator: max log(D(real)) + log(1 - D(G(z)))\n",
    "        noise = torch.randn(batch_size, product_dims)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real).view(-1)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_real + lossD_fake)/2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "        \n",
    "        # Train Generator min log(1 - D(G(z))) -> max log(D(G(z)))\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        if ((batch_idx + 1) % 50 == 0) or batch_idx == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}] \\ \"\n",
    "                f\"Step [{batch_idx + 1}/{n_total_steps}] \\ \"\n",
    "                f\"Loss D: {lossD:.4f}, Loss G: {lossG:.4f}\"\n",
    "            )\n",
    "            \n",
    "            if batch_idx == 0:\n",
    "                with torch.no_grad():\n",
    "                    fake = gen(fixed_noise)\n",
    "                    print(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abef15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(X[~X.index.isin(train_inds)].values.astype(np.float32)),\n",
    "    torch.tensor(y[~y.index.isin(train_inds)].values.astype(np.float32))\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3efd7737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>DOB</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>EMAIL</th>\n",
       "      <th>PHONE_NUMBER</th>\n",
       "      <th>POST_CODE</th>\n",
       "      <th>CITY</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>POST_SUBSCRIBED</th>\n",
       "      <th>SMS_SUBSCRIBED</th>\n",
       "      <th>EMAIL_SUBSCRIBED</th>\n",
       "      <th>PHONE_SUBSCRIBED</th>\n",
       "      <th>SOCIAL_SUBSCRIBED</th>\n",
       "      <th>ANONYMISE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3e0698d7a4</td>\n",
       "      <td>New</td>\n",
       "      <td>Male</td>\n",
       "      <td>1988-04-16</td>\n",
       "      <td>Zelda</td>\n",
       "      <td>Schene</td>\n",
       "      <td>Zelda.SCHENE@yahoo.com</td>\n",
       "      <td>799947361</td>\n",
       "      <td>BH16</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>UK</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3e06a74d39</td>\n",
       "      <td>Lookers</td>\n",
       "      <td>Male</td>\n",
       "      <td>2003-04-13</td>\n",
       "      <td>Betty</td>\n",
       "      <td>Asherman</td>\n",
       "      <td>Betty.ASHERMAN@yahoo.com</td>\n",
       "      <td>799947361</td>\n",
       "      <td>M1</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3e06b7960c</td>\n",
       "      <td>Loyal</td>\n",
       "      <td>Male</td>\n",
       "      <td>1972-04-20</td>\n",
       "      <td>Gusta</td>\n",
       "      <td>Leibowitz</td>\n",
       "      <td>Gusta.LEIBOWITZ@yahoo.com</td>\n",
       "      <td>799947361</td>\n",
       "      <td>BH16</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3e06ed2cfb</td>\n",
       "      <td>Need-based</td>\n",
       "      <td>Male</td>\n",
       "      <td>2002-04-13</td>\n",
       "      <td>Mona</td>\n",
       "      <td>Roca</td>\n",
       "      <td>Mona.ROCA@yahoo.com</td>\n",
       "      <td>799947361</td>\n",
       "      <td>BH16</td>\n",
       "      <td>Austin</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3e07060e00</td>\n",
       "      <td>Loyal</td>\n",
       "      <td>Female</td>\n",
       "      <td>1998-04-14</td>\n",
       "      <td>Lesley</td>\n",
       "      <td>Bieck</td>\n",
       "      <td>Lesley.BIECK@yahoo.com</td>\n",
       "      <td>799947361</td>\n",
       "      <td>M1</td>\n",
       "      <td>Gothenburg</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536779</th>\n",
       "      <td>83975980ac</td>\n",
       "      <td>Loyal</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-04-16</td>\n",
       "      <td>Glenn</td>\n",
       "      <td>Rorman</td>\n",
       "      <td>Glenn.RORMAN@yahoo.com</td>\n",
       "      <td>799947361</td>\n",
       "      <td>ME20</td>\n",
       "      <td>Kiruna</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536780</th>\n",
       "      <td>839766e877</td>\n",
       "      <td>Impulse</td>\n",
       "      <td>Male</td>\n",
       "      <td>1998-04-14</td>\n",
       "      <td>Shanell</td>\n",
       "      <td>Hartkorn</td>\n",
       "      <td>Shanell.HARTKORN@yahoo.com</td>\n",
       "      <td>799947361</td>\n",
       "      <td>ME20</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>UK</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536781</th>\n",
       "      <td>8397796cf8</td>\n",
       "      <td>Need-based</td>\n",
       "      <td>Female</td>\n",
       "      <td>1995-04-15</td>\n",
       "      <td>Delma</td>\n",
       "      <td>Lambo</td>\n",
       "      <td>Delma.LAMBO@yahoo.com</td>\n",
       "      <td>799947361</td>\n",
       "      <td>L15</td>\n",
       "      <td>Kiruna</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536782</th>\n",
       "      <td>83978b079a</td>\n",
       "      <td>New</td>\n",
       "      <td>Female</td>\n",
       "      <td>1983-04-18</td>\n",
       "      <td>Christiana</td>\n",
       "      <td>Dakin</td>\n",
       "      <td>Christiana.DAKIN@yahoo.com</td>\n",
       "      <td>799947361</td>\n",
       "      <td>M1</td>\n",
       "      <td>London</td>\n",
       "      <td>UK</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536783</th>\n",
       "      <td>8397b5dfd1</td>\n",
       "      <td>Need-based</td>\n",
       "      <td>Female</td>\n",
       "      <td>1992-04-15</td>\n",
       "      <td>Lovell</td>\n",
       "      <td>Kollmorgen</td>\n",
       "      <td>Lovell.KOLLMORGEN@yahoo.com</td>\n",
       "      <td>799947361</td>\n",
       "      <td>L15</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536784 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID        TYPE  GENDER         DOB  FIRST_NAME   LAST_NAME  \\\n",
       "0       3e0698d7a4         New    Male  1988-04-16       Zelda      Schene   \n",
       "1       3e06a74d39     Lookers    Male  2003-04-13       Betty    Asherman   \n",
       "2       3e06b7960c       Loyal    Male  1972-04-20       Gusta   Leibowitz   \n",
       "3       3e06ed2cfb  Need-based    Male  2002-04-13        Mona        Roca   \n",
       "4       3e07060e00       Loyal  Female  1998-04-14      Lesley       Bieck   \n",
       "...            ...         ...     ...         ...         ...         ...   \n",
       "536779  83975980ac       Loyal    Male  1991-04-16       Glenn      Rorman   \n",
       "536780  839766e877     Impulse    Male  1998-04-14     Shanell    Hartkorn   \n",
       "536781  8397796cf8  Need-based  Female  1995-04-15       Delma       Lambo   \n",
       "536782  83978b079a         New  Female  1983-04-18  Christiana       Dakin   \n",
       "536783  8397b5dfd1  Need-based  Female  1992-04-15      Lovell  Kollmorgen   \n",
       "\n",
       "                              EMAIL  PHONE_NUMBER POST_CODE        CITY  \\\n",
       "0            Zelda.SCHENE@yahoo.com     799947361      BH16   Liverpool   \n",
       "1          Betty.ASHERMAN@yahoo.com     799947361        M1   Stockholm   \n",
       "2         Gusta.LEIBOWITZ@yahoo.com     799947361      BH16     Seattle   \n",
       "3               Mona.ROCA@yahoo.com     799947361      BH16      Austin   \n",
       "4            Lesley.BIECK@yahoo.com     799947361        M1  Gothenburg   \n",
       "...                             ...           ...       ...         ...   \n",
       "536779       Glenn.RORMAN@yahoo.com     799947361      ME20      Kiruna   \n",
       "536780   Shanell.HARTKORN@yahoo.com     799947361      ME20     Glasgow   \n",
       "536781        Delma.LAMBO@yahoo.com     799947361       L15      Kiruna   \n",
       "536782   Christiana.DAKIN@yahoo.com     799947361        M1      London   \n",
       "536783  Lovell.KOLLMORGEN@yahoo.com     799947361       L15   Stockholm   \n",
       "\n",
       "       COUNTRY  POST_SUBSCRIBED  SMS_SUBSCRIBED  EMAIL_SUBSCRIBED  \\\n",
       "0           UK             True            True              True   \n",
       "1       Sweden             True            True              True   \n",
       "2           US             True            True              True   \n",
       "3           US             True            True              True   \n",
       "4       Sweden             True            True              True   \n",
       "...        ...              ...             ...               ...   \n",
       "536779  Sweden             True            True              True   \n",
       "536780      UK             True            True              True   \n",
       "536781  Sweden             True            True              True   \n",
       "536782      UK             True            True              True   \n",
       "536783  Sweden             True            True              True   \n",
       "\n",
       "        PHONE_SUBSCRIBED  SOCIAL_SUBSCRIBED  ANONYMISE  \n",
       "0                   True               True       True  \n",
       "1                   True               True       True  \n",
       "2                   True               True       True  \n",
       "3                   True               True       True  \n",
       "4                   True               True       True  \n",
       "...                  ...                ...        ...  \n",
       "536779              True               True       True  \n",
       "536780              True               True       True  \n",
       "536781              True               True       True  \n",
       "536782              True               True       True  \n",
       "536783              True               True       True  \n",
       "\n",
       "[536784 rows x 17 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f73830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
