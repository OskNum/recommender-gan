{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac9fd987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189ade17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ccfb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(21, 21),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(21, 21),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(21, 21),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(21, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear_relu_stack(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "957806e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "seed = 42\n",
    "num_epochs = 5\n",
    "batch_size = 512\n",
    "learning_rate = 3e-4\n",
    "train_size = 0.9\n",
    "\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49656843",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/train/X.csv').reset_index(drop=True)\n",
    "y = pd.read_csv('data/train/y.csv').reset_index(drop=True)\n",
    "\n",
    "train_inds = random.sample(list(X.index.values), int(train_size*len(X.index)))\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X.iloc[train_inds].values.astype(np.float32)),\n",
    "    torch.tensor(y.iloc[train_inds].values.astype(np.float32))\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(X[~X.index.isin(train_inds)].values.astype(np.float32)),\n",
    "    torch.tensor(y[~y.index.isin(train_inds)].values.astype(np.float32))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42ae2dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b963c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "287a1af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1000/7537], Loss: 1.0958\n",
      "Epoch [1/5], Step [2000/7537], Loss: 1.0975\n",
      "Epoch [1/5], Step [3000/7537], Loss: 1.0966\n",
      "Epoch [1/5], Step [4000/7537], Loss: 1.0915\n",
      "Epoch [1/5], Step [5000/7537], Loss: 1.0932\n",
      "Epoch [1/5], Step [6000/7537], Loss: 1.0971\n",
      "Epoch [1/5], Step [7000/7537], Loss: 1.0996\n",
      "Epoch [2/5], Step [1000/7537], Loss: 1.0960\n",
      "Epoch [2/5], Step [2000/7537], Loss: 1.0939\n",
      "Epoch [2/5], Step [3000/7537], Loss: 1.0987\n",
      "Epoch [2/5], Step [4000/7537], Loss: 1.0926\n",
      "Epoch [2/5], Step [5000/7537], Loss: 1.0959\n",
      "Epoch [2/5], Step [6000/7537], Loss: 1.0954\n",
      "Epoch [2/5], Step [7000/7537], Loss: 1.0928\n",
      "Epoch [3/5], Step [1000/7537], Loss: 1.0994\n",
      "Epoch [3/5], Step [2000/7537], Loss: 1.0985\n",
      "Epoch [3/5], Step [3000/7537], Loss: 1.0990\n",
      "Epoch [3/5], Step [4000/7537], Loss: 1.0963\n",
      "Epoch [3/5], Step [5000/7537], Loss: 1.0967\n",
      "Epoch [3/5], Step [6000/7537], Loss: 1.0945\n",
      "Epoch [3/5], Step [7000/7537], Loss: 1.0971\n",
      "Epoch [4/5], Step [1000/7537], Loss: 1.0984\n",
      "Epoch [4/5], Step [2000/7537], Loss: 1.0972\n",
      "Epoch [4/5], Step [3000/7537], Loss: 1.0998\n",
      "Epoch [4/5], Step [4000/7537], Loss: 1.0995\n",
      "Epoch [4/5], Step [5000/7537], Loss: 1.0997\n",
      "Epoch [4/5], Step [6000/7537], Loss: 1.0965\n",
      "Epoch [4/5], Step [7000/7537], Loss: 1.0948\n",
      "Epoch [5/5], Step [1000/7537], Loss: 1.0961\n",
      "Epoch [5/5], Step [2000/7537], Loss: 1.0994\n",
      "Epoch [5/5], Step [3000/7537], Loss: 1.0959\n",
      "Epoch [5/5], Step [4000/7537], Loss: 1.0976\n",
      "Epoch [5/5], Step [5000/7537], Loss: 1.0961\n",
      "Epoch [5/5], Step [6000/7537], Loss: 1.0938\n",
      "Epoch [5/5], Step [7000/7537], Loss: 1.0957\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (products, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        \n",
    "        products = products.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass and loss calculation\n",
    "        outputs = model(products)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if (i+1) % 1000 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "    writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1f872f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9298, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "        [0.7692, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.7926, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.9197, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0502, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254a195e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
